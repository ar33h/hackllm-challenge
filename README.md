# Llama3-Groq-Streamlit Chat Application
This project showcases a chat application built with Streamlit that integrates Llama3 models via the Groq platform. It's designed to offer speedy real-time AI-driven chat functionalities, making the most of Llama3's capabilities within an interactive web interface.

## About the Challenge
- **Llama3 Integration**: Leverages the Llama3 and other major models, such as Mixtral and Gemma, to provide intelligent and context-aware responses.
- **Groq Platform**: Utilizes Groq's powerful computation capabilities to ensure fast and efficient model responses.
- **Streamlit Interface**: Offers a user-friendly web interface that allows users to interact with the AI dynamically.
- **Real-Time Responses**: Engineered to handle user inputs and deliver AI responses in real time.

## Configuration
### Obtaining Groq API Key
To use this application, you'll need an API key from Groq. Visit the [Groq API Documentation](https://console.groq.com/docs/quickstart) to learn how to obtain one.

### Setting Up Your Environment
Once you have your API key, open the `.env` file and replace `YOUR_API_KEY_HERE` with your Groq API key.

## Running the Application
To run the application, use the following command: ```streamlit run app.py```

